{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb82e54e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea859db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "import json\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3d3a4",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12666eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "SPEAKER_ATTRIBUTES_DATA = DATA_FOLDER+\"speaker_attributes.parquet\"\n",
    "WIKIDATA_LABELS = DATA_FOLDER + \"wikidata_labels_descriptions_quotebank.csv.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd42e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the wikilabels dataframe\n",
    "wiki_labels = pd.read_csv(WIKIDATA_LABELS, compression='bz2', index_col='QID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd0f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the attribute dataframe\n",
    "attributes = pd.read_parquet(SPEAKER_ATTRIBUTES_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc4119",
   "metadata": {},
   "source": [
    "## Keep only the attributes of interest and rename the column for the future merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e938b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = attributes.get(['gender','date_of_birth','occupation','id', 'ethnic_group', 'academic_degree', 'religion'])\n",
    "attributes.rename(columns={'id':'qids'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26aa7ac",
   "metadata": {},
   "source": [
    "## Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102a8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_chunk_attributes(chunk):\n",
    "        \"\"\"\n",
    "        Merge the chunk with the .parquet file with the wikidata attribute of the speaker.\n",
    "        Before doing it, keep only the quotes with a single qid.\n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        chunk: dataframe\n",
    "    \n",
    "        Returns:\n",
    "        ----------\n",
    "        chunk: the dataframe with readable information\n",
    "    \n",
    "        \"\"\"\n",
    "        #Remove the quotes with speaker linked to many qids: we cannot know which of the homonym is the real speaker\n",
    "        chunk.drop(chunk[chunk['qids'].map(len) > 1].index, inplace=True)\n",
    "        #Keep only the first qids\n",
    "        chunk['qids'] = chunk['qids'].apply(lambda x: x[0])\n",
    "        #Merge the chunk with the parquet file\n",
    "        chunk_merged = chunk.merge(attributes)\n",
    "        return chunk_merged\n",
    "    \n",
    "def match_code_label(code):\n",
    "    \"\"\"\n",
    "        Match the wikidata code 'Q...' with its readable information\n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        code: string\n",
    "    \n",
    "        Returns:\n",
    "        ----------\n",
    "        string : the readable information\n",
    "    \n",
    "    \"\"\"\n",
    "    if code == None:\n",
    "        return None\n",
    "    \n",
    "    if code in wiki_labels.index:\n",
    "        return wiki_labels.loc[code]['Label']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def render_info_readable(chunk):\n",
    "    \"\"\"\n",
    "    Replace the wikidata code 'Q...' by readable information. Drop all rows containing a None.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    chunk: dataframe\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    chunk: the dataframe with readable information\n",
    "    \n",
    "    \"\"\"\n",
    "    for col in ['gender', 'occupation', 'ethnic_group', 'academic_degree', 'religion']:\n",
    "        chunk[col] = chunk[col].apply(lambda x: [match_code_label(i) for i in x] if (x is not None) else (None))\n",
    "\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def filter_gender(chunk):\n",
    "        \"\"\"\n",
    "        Keeps only the first gender in the list of genders, and drop the quotations with unknown gender.\n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        chunk: dataframe\n",
    "    \n",
    "        Returns:\n",
    "        ----------\n",
    "        chunk: the dataframe with only one gender per row.\n",
    "    \n",
    "        \"\"\"  \n",
    "        #Remove the quotations for which the gender of the speaker in unknown\n",
    "        chunk.dropna(axis = 0, subset = ['gender'], inplace = True)\n",
    "        #Keep only the first gender in the list \n",
    "        chunk['gender'] = chunk['gender'].apply(lambda x: x[0])\n",
    "        return chunk\n",
    "\n",
    "\n",
    "    \n",
    "def get_age(chunk, actual_year):\n",
    "    \"\"\"\n",
    "    Replace the column 'date_of_birth' by a column age, with the age calculated at the time of the quotation.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    chunk: dataframe\n",
    "    actual_year: year of the dataframe\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    chunk: the dataframe with the age of speakers reported\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    chunk.dropna(axis = 0, subset = ['date_of_birth'], inplace = True)\n",
    "    chunk['date_of_birth'] = chunk['date_of_birth'].apply(lambda x: x[0]) \n",
    "    chunk['date_of_birth'] = chunk['date_of_birth'].apply(lambda x: int(int(actual_year) - float(x[1:5]))) \n",
    "    chunk.rename(columns={\"date_of_birth\": \"age\"}, inplace = True)\n",
    "    return chunk\n",
    "\n",
    "def preprocess_data(year):\n",
    "    \"\"\"\n",
    "    Preprocess the data by:\n",
    "    -merging the data with the attributes of the speakers\n",
    "    -rendering the information readable \n",
    "    -removing unknown gender\n",
    "    -calculating age and removing unknown ages\n",
    "\n",
    "    The function stores the preprocess data in files named \"chunk-i-year.json.bz2\", with i=1,...n for n \n",
    "    the number of chunks.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    year: string year of the dataframe to process. Expected values: '2015', '2016', '2017-before', \n",
    "    '2017-after', '2018', '2019' or '2020'.\n",
    "    \n",
    "    \"\"\"\n",
    "    DATA_TO_PROCESS = DATA_FOLDER + f'quotes-{year}-reduced.json.bz2'\n",
    "    i = 0\n",
    "    with pd.read_json(DATA_TO_PROCESS, lines=True, compression='bz2', chunksize=1000000) as df_reader:\n",
    "        for chunk in df_reader:\n",
    "            i +=1\n",
    "            chunk_merged = merge_chunk_attributes(chunk)\n",
    "            chunk_readable = render_info_readable(chunk_merged)\n",
    "            chunk_filtered = filter_gender(chunk_readable)\n",
    "            if year == '2017-after' or year == '2017-before':\n",
    "                chunk_aged = get_age(chunk_filtered, '2017')\n",
    "            else:\n",
    "                chunk_aged = get_age(chunk_filtered, year)\n",
    "            if year == '2017-after' or year == '2017-before' or year == '2018':\n",
    "                chunk_aged.drop(columns = ['date'], inplace = True)\n",
    "            chunk_aged.to_json(DATA_FOLDER + f'chunk-{str(i)}-{str(year)}.json.bz2')\n",
    "\n",
    "def create_sample_from_year(year):\n",
    "    \"\"\"\n",
    "    Create a sample for the year by randomly sampling 33333 quotations in the first 3 chunks created by \n",
    "    the function preprocess_data. The sample results in 99999 quotations for the given year. This function \n",
    "    stores the created sample in a file named \"sample-year.json.bz2\".\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    year: string. Year of the dataframe to process. Expected values: '2015', '2016', '2017-before', \n",
    "    '2017-after', '2018', '2019' or '2020'.\n",
    "    \n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    for k in range(3):\n",
    "        df_chunk = pd.read_json(DATA_FOLDER + f'chunk-{str(k+1)}-{year}.json.bz2')\n",
    "        sample.append(df_chunk.sample(math.floor(100000/3)))\n",
    "    df_sample = pd.concat(sample, ignore_index=True)\n",
    "    df_sample.to_json(DATA_FOLDER + f'sample-{year}.json.bz2')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f04402",
   "metadata": {},
   "source": [
    "## Preprocess all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2949ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2015', '2016', '2017-before', '2017-after', '2018', '2019', '2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78294a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    preprocess_data(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1776b8",
   "metadata": {},
   "source": [
    "## Create dataframe ready for observational data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28736f9",
   "metadata": {},
   "source": [
    "At this stage, we realized that the attributes `religion` and `ethnic_group` were very rarely known. So we decided to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e14178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observational_data(year, nb_chunk):\n",
    "    chunks=[]\n",
    "    for i in range(nb_chunk):\n",
    "        chunk = pd.read_json(DATA_FOLDER+f'chunk-{str(i+1)}-{year}.json.bz2')\n",
    "        chunk.drop(['religion', 'ethnic_group'], axis = 1, inplace = True)\n",
    "        chunk.dropna(inplace = True)\n",
    "        chunks.append(chunk)\n",
    "        df_obs = pd.concat(chunks)\n",
    "        df_obs.reset_index(drop=True, inplace=True)\n",
    "        df_obs.to_json(DATA_FOLDER + f'observational-{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f47d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2015', '2016', '2017-before', '2017-after', '2018', '2019', '2020']\n",
    "nb_chunks = [10, 7, 9, 4, 13, 10, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6913974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, nb_chunk in zip(years, nb_chunks):\n",
    "    create_observational_data(year, nb_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4c4ea",
   "metadata": {},
   "source": [
    "Now that we have created one file for each year, let's concatenate it into a single dataframe that we will use for the observational study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6232979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2015 = pd.read_json(DATA_FOLDER+f'observational-2015.json.bz2')\n",
    "quotes_2016 = pd.read_json(DATA_FOLDER+f'observational-2016.json.bz2')\n",
    "quotes_2017_before = pd.read_json(DATA_FOLDER+f'observational-2017-before.json.bz2')\n",
    "quotes_2017_after = pd.read_json(DATA_FOLDER+f'observational-2017-after.json.bz2')\n",
    "quotes_2018 = pd.read_json(DATA_FOLDER+f'observational-2018.json.bz2')\n",
    "quotes_2019 = pd.read_json(DATA_FOLDER+f'observational-2019.json.bz2')\n",
    "quotes_2020 = pd.read_json(DATA_FOLDER+f'observational-2018.json.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd52aee",
   "metadata": {},
   "source": [
    "We add a column `label`: 0 if the quotation is said before #MeToo, 1 if the quotation is said after #MeToo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdfae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2015['label'] = 0\n",
    "quotes_2016['label'] = 0\n",
    "quotes_2017_before['label'] = 0\n",
    "quotes_2017_after['label'] = 1\n",
    "quotes_2018['label'] = 1\n",
    "quotes_2019['label'] = 1\n",
    "quotes_2020['label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f57d5",
   "metadata": {},
   "source": [
    "We also add a column `year` to still be able to access the year of the quote if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f5597fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2015['year'] = 2015\n",
    "quotes_2016['year'] = 2016\n",
    "quotes_2017_before['year'] = 2017\n",
    "quotes_2017_after['year'] = 2017\n",
    "quotes_2018['year'] = 2018\n",
    "quotes_2019['year'] = 2019\n",
    "quotes_2020['year'] = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d8f9c",
   "metadata": {},
   "source": [
    "Let's finally create our final dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c49cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = pd.concat([quotes_2015, quotes_2016, quotes_2017_before, \n",
    "                    quotes_2017_after, quotes_2018, quotes_2019, quotes_2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f1f03",
   "metadata": {},
   "source": [
    "We will remove all quotations when the gender is not `male` or `female`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac94d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.drop(quotes[(quotes['gender'] != 'female') & (quotes['gender'] != 'male')].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "834b51ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am convinced that this conflict won't be sol...</td>\n",
       "      <td>Angela Merkel</td>\n",
       "      <td>Q567</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>61</td>\n",
       "      <td>[politician, physicist, statesperson, chemist]</td>\n",
       "      <td>[doctorate]</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreed that the E.U. should take further measu...</td>\n",
       "      <td>Angela Merkel</td>\n",
       "      <td>Q567</td>\n",
       "      <td>6</td>\n",
       "      <td>female</td>\n",
       "      <td>61</td>\n",
       "      <td>[politician, physicist, statesperson, chemist]</td>\n",
       "      <td>[doctorate]</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany will continue to do everything to supp...</td>\n",
       "      <td>Angela Merkel</td>\n",
       "      <td>Q567</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>61</td>\n",
       "      <td>[politician, physicist, statesperson, chemist]</td>\n",
       "      <td>[doctorate]</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There has already been voluntary debt forgiven...</td>\n",
       "      <td>Angela Merkel</td>\n",
       "      <td>Q567</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>61</td>\n",
       "      <td>[politician, physicist, statesperson, chemist]</td>\n",
       "      <td>[doctorate]</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           quotation        speaker  qids  \\\n",
       "0  I am convinced that this conflict won't be sol...  Angela Merkel  Q567   \n",
       "1  agreed that the E.U. should take further measu...  Angela Merkel  Q567   \n",
       "2  Germany will continue to do everything to supp...  Angela Merkel  Q567   \n",
       "3  There has already been voluntary debt forgiven...  Angela Merkel  Q567   \n",
       "\n",
       "   numOccurrences  gender  age  \\\n",
       "0               1  female   61   \n",
       "1               6  female   61   \n",
       "2               1  female   61   \n",
       "3               1  female   61   \n",
       "\n",
       "                                       occupation academic_degree  label  year  \n",
       "0  [politician, physicist, statesperson, chemist]     [doctorate]      0  2015  \n",
       "1  [politician, physicist, statesperson, chemist]     [doctorate]      0  2015  \n",
       "2  [politician, physicist, statesperson, chemist]     [doctorate]      0  2015  \n",
       "3  [politician, physicist, statesperson, chemist]     [doctorate]      0  2015  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88484b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f73902f5",
   "metadata": {},
   "source": [
    "quotes.to_json(DATA_FOLDER + 'data_observational.json.bz2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
