{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the year of the dataset that you want to reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2020\n",
    "INITIAL_DATASET = f\"quotes-{str(YEAR)}.json.bz2\"\n",
    "REDUCED_DATASET = f\"quotes-{str(YEAR)}-reduced.json.bz2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For years 2015, 2016, 2018, 2019 and 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we decided to remove all unknown speakers. Then, we kept only the speaker for which the probability is higher than 0.7. Indeed, we want a high probability to have the real speaker, since our analysis mainly focus on the characteristics of the speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the columns that are not useful in our analysis: 'quoteID', 'date', 'probas', 'urls', 'phase'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce a dataset by keeping known speakers with a probability > 0.7\n",
    "#drop columns ['quoteID', 'date', 'probas', 'urls', 'phase']\n",
    "\n",
    "path_to_file = '/content/drive/MyDrive/Quotebank/' + INITIAL_DATASET\n",
    "path_to_out = '/content/drive/MyDrive/data/' + REDUCED_DATASET\n",
    "\n",
    "if YEAR in [2017, 2018]:\n",
    "    keys_to_remove = ['quoteID', 'probas', 'urls', 'phase']\n",
    "else:\n",
    "    keys_to_remove = ['quoteID', 'date', 'probas', 'urls', 'phase']\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            if (instance['speaker'] != None) and (instance['probas'][0][1] > 0.7):\n",
    "                for k in keys_to_remove:\n",
    "                    del instance[k]\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2017, we decided to separate the file into to separate files: one with the quotations before the #MeToo movement, and one with the quotations after the movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017, create 2 separated files: one before #MeToo (October) and one after\n",
    "path_to_file = '/content/drive/MyDrive/data/quotes-2017-reduced.json.bz2'\n",
    "path_to_out = '/content/drive/MyDrive/data/quoted-2017-reduced-before.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            instance_date = datetime.datetime.strptime(instance['date'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            if (instance_date.month < 10):\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8'))    \n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = '/content/drive/MyDrive/data/quotes-2017-reduced.json.bz2'\n",
    "path_to_out = '/content/drive/MyDrive/data/quoted-2017-reduced-after.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            instance_date = datetime.datetime.strptime(instance['date'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            if (instance_date.month >= 10):\n",
    "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the data are now stored into file named \"quotes-year-reduced.json.bz2\". These files will be used for further preprocessing. See [here](Preprocessing.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
